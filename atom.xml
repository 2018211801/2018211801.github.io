<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xiaochen</title>
  
  
  <link href="http://2018211801.github.io/xiaochen/atom.xml" rel="self"/>
  
  <link href="http://2018211801.github.io/xiaochen/"/>
  <updated>2025-04-10T08:48:16.492Z</updated>
  <id>http://2018211801.github.io/xiaochen/</id>
  
  <author>
    <name>xiaochen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>about</title>
    <link href="http://2018211801.github.io/xiaochen/about/"/>
    <id>http://2018211801.github.io/xiaochen/about/</id>
    <published>2024-12-10T14:12:52.000Z</published>
    <updated>2025-04-10T08:48:16.492Z</updated>
    
    <content type="html"><![CDATA[<p>Hi~ I am <strong>Xiaochen Wang(王晓晨)</strong>, a master student at the School of Software and Microelectronics, Peking University. I study at National Key Laboratory for Multimedia Information Processing supervised by Prof. Zhifang Sui. Previously, I completed my bachelor’s degree at Beijing University of Posts and Telecommunications (BUPT) and awarded Beijing Outstanding Graduate in July 2022.</p><p><font color="red"> <strong>I am looking for a Ph.D. opportunity, please contact me if you are interested!</strong> </font></p><h3 id="Research-Interests"><a href="#Research-Interests" class="headerlink" title="Research Interests:"></a>Research Interests:</h3><p>My research interests lie in LLM, MLLM and unified multimodal generation. My research mainly focus on How to Enhance the Reasoning Capability of LLM efficiently?  My past work includes efficient post-training, model merging and evaluation. </p><p>I am happy to discuss potential collaboration opportunities, feel free to reach out!</p><h3 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h3><p>Full list of papers can be found at <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=9hxxM1UAAAAJ">Google Scholar</a>.<br>* indicates equal contribution</p><ul><li><p><strong>Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization</strong> [<a href="https://arxiv.org/abs/2503.23733">Link</a>]</p><p> <em>Yiyang Du</em>*, <strong>Xiaochen Wang*</strong>, Chi Chen, Jiabo Ye, Yiru Wang, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Zhifang Sui, Maosong Sun, Yang Liu*</p><p> [CVPR 2025]</p></li><li><p><strong>SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine</strong> [<a href="https://arxiv.org/abs/2410.17021">Link</a>]</p><p><em><strong>Xiaochen Wang</strong>, Junqing He, Zhe Yang, Yiru Wang, Xiangdi Meng, Kunhao Pan, Zhifang Sui</em></p><p>[NAACL 2024]</p></li><li><p><strong>Beyond Single Frames: Can LMMs Comprehend Temporal and Contextual Narratives in Image Sequences?</strong><a href="https://arxiv.org/abs/2502.13925">[Link]</a><br><em><strong>Xiaochen Wang</strong></em>, Heming Xia*, Jialin Song, Longyu Guan, Yixin Yang, Qingxiu Dong, Weiyao Luo, Yifan Pu, Yiru Wang,*<br><em>Xiangdi Meng, Wenjie Li, Zhifang Sui</em><br>[ACL 2025 under review]</p></li><li><p><strong>Statistical Dataset Evaluation: Reliability, Difficulty, and<br>Validity</strong> <a href="https://arxiv.org/abs/2212.09272">[Link]</a></p><p><em>Chengwen Wang*, Qingxiu Dong*, <strong>Xiaochen Wang</strong>, Haitao Wang, Zhifang Sui</em></p><p>[Natural Language Engineering under minor revision]</p></li><li><p><strong>PeriodicLoRA: Breaking the Low-Rank Bottleneck in LoRA<br>Optimization</strong> <a href="https://arxiv.org/abs/2402.16141">[Link]</a></p><p><em>Xiangdi Meng, Damai Dai, Weiyao Luo, Zhe Yang, Shaoxiang Wu, <strong>Xiaochen Wang</strong>, Peiyi Wang, Qingxiu Dong, Liang Chen, Zhifang Sui</em></p><p><em>arxiv</em></p></li><li><p><strong>Abnormal Event Detection via Hypergraph Contrastive Learning</strong>  <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch80">[Link]</a></p><p><em>Bo Yan, Cheng Yang, Chuan Shi, Jiawei Liu, <strong>Xiaochen Wang</strong></em></p><p><em>SDM 2023</em></p></li></ul><h3 id="Internship"><a href="#Internship" class="headerlink" title="Internship"></a>Internship</h3><p><strong>MSRA</strong>  </p><p>Jan. 2025 – May. 2025<br>Research Intern Beijing, China<br>Supervisor: <em>Dr. Yuhui Yuan and Baining Guo</em></p><p><strong>THUNLP</strong> </p><p>Aug. 2024 – Nov. 2024<br>Research Intern Beijing, China<br>Supervisor: <em>Prof. Yang Liu and Asst. Prof. Peng Li</em></p><p><strong>International Digital Economy Academy</strong> </p><p>Nov. 2023 – Mar. 2023<br>Research Intern Shenzhen, China<br>Supervisor: <em>Dr. Junqing He and Kunhao Pan</em></p><p><strong>Shanghai AI LAB &amp; SenseTime</strong> </p><p>Jul. 2023 – Oct. 2023<br>Research Intern Beijing, China<br>Supervisor: <em>Dr. Baoxiang Li</em></p><h3 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h3><p> <strong>AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization</strong></p><p><em>Yiyang Du*, <strong>Xiaochen Wang</strong>*,Chi Chen, Peng Li, Zhifang Sui, Yang Liu</em></p><ul><li><strong>Problems:</strong> Different VLLMs have variations in their visual models and connector components, which pose challenges for integrating VLLM models. Additionally, the hyperparameter selection for existing model fusion methods generally requires labeled data, imposing certain limitations.</li><li><strong>Solutions:</strong> We made the first attempt to do merging in heterogeneous MLLMs, including mapping, merging and searching to solve architectural differences and achieve best performance without labeled data. </li><li><strong>Results:</strong>  Extensive experiments show that our AdaMMS outperforms existing model merging methods on multiple vision-language benchmarks. Additionally, our merged model exceeds Qwen2-VL-7B in most tasks, achieving state-of-the-art performance at the 7B scale.</li></ul><img src="/images/adamms.png" width="500"><p><a href="https://arxiv.org/abs/2402.16141"><strong>PeriodicLoRA: Breaking the Low-Rank Bottleneck in LoRA Optimization</strong></a></p><p><em>Xiangdi Meng, Damai Dai, Weiyao Luo, Zhe Yang, Shaoxiang Wu, <strong>Xiaochen Wang</strong>, Peiyi Wang, Qingxiu Dong, Liang Chen, Zhifang Sui</em></p><ul><li><p><strong>Problems:</strong> Rank adjustment during training is fixed and optimal rank value is uncertain. Besides, parameter scale for LoRA conflicts with memory usage.</p></li><li><p><strong>Solutions:</strong> We propose PeriodicLoRA (PLoRA), a method that periodically unloads the LoRA matrices back to the original backbone with a ratio. This process generates a higher rank update matrix by accumulating low rank matrices without extra memory usage.</p></li><li><p><strong>Results:</strong> Experimental findings demonstrate that PLoRA with low rank outperforms LoRA, improving training speed by 80%.</p></li></ul><img src="https://arxiv.org/html/2402.16141v1/x1.png" width="600"><p> <a href="https://arxiv.org/pdf/2410.17021"><strong>SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine</strong></a> </p><p><em><strong>Xiaochen Wang</strong>, Junqing He, Zhe Yang, Yiru Wang, Xiangdi Meng, Kunhao Pan, Zhifang Sui</em></p><ul><li><strong>Problems:</strong>   Large Language models (LLMs) with few-shot methods underperform in multi-hop reasoning because of hallucination, error propagation and limited context length. </li><li><strong>Solutions:</strong>  We design a zero-shot FSM framework based on Finite State Machine that explicitly supports the model in the phases of decomposition, retrieval, and verification. FSM tackles one task at a time, decides the next action based on the current results and states.</li><li><strong>Results:</strong> Our results have a more standardized format and outperform COT on challenging datasets like Musique.</li></ul><img src="https://arxiv.org/html/2410.17021v1/x1.png" width="600"><p><strong><a href="https://arxiv.org/abs/2502.13925">Beyond Single Frames: Can LMMs Comprehend Temporal and Contextual Narratives in Image Sequences?</a></strong></p><p><em><strong>Xiaochen Wang</strong></em>, Heming Xia*, Jialin Song, Longyu Guan, Yixin Yang, Qingxiu Dong, Weiyao Luo, Yifan Pu, Yiru Wang, Xiangdi Meng, Wenjie Li, Zhifang Sui*</p><ul><li><strong>Problems:</strong> To eval whether LMMs can comprehend temporal relationship in image sequences, </li><li><strong>Solutions:</strong>  We utilize comic strips as the core component of the dataset, and design three tasks: visual narrative comprehension, contextual frame prediction, and temporal narrative reordering.</li><li><strong>Results:</strong> GPT-4o achieves only 23.93% accuracy in the reordering subtask, which is 56.07% lower than human performance, which underscores the fundamental challenges in sequential understanding that remain in the development of LMMs.</li></ul><img src="https://arxiv.org/html/2502.13925v1/x3.png" width="700"><p><a href="https://arxiv.org/abs/2212.09272"><strong>Statistical Dataset Evaluation: Reliability, Difficulty, and Validit</strong></a> </p><p><em>Chengwen Wang*, Qingxiu Dong*, <strong>Xiaochen Wang</strong>, Haitao Wang, Zhifang Sui</em></p><ul><li><p><strong>Problems:</strong>  Existing datasets have exposed numerous issues, leading to biased models and unreliable evaluation, without human evaluation of dataset quality. </p></li><li><p><strong>Solutions:</strong>  We seek to understand the statistical properties of datasets and address three fundamental dimensions: reliability, difficulty, and validity. Taking the Named Entity Recognition datasets as a case study, we introduce $9$ statistical metrics.</p></li><li><p><strong>Results:</strong> We studied how the scores of datasets on statistical metrics impact model performance and advocate for assessing dataset quality or making targeted improvements to datasets before training or testing models.</p></li></ul><h3 id="Awards"><a href="#Awards" class="headerlink" title="Awards"></a>Awards</h3><p>Beijing Outstanding Graduate in BUPT (2022)<br>Merit Student, BUPT (2020)</p><h3 id="Services"><a href="#Services" class="headerlink" title="Services"></a>Services</h3><p><strong>Reviewer</strong></p><p>ARR</p><p><strong>Secretary, Youth League Branch</strong><br> <em>Undergraduate</em></p><p>Led the class to earn the First-Class Outstanding Class Award. And honored with the Excellent Student Leader title for exceptional leadership.</p><p><strong>Organization Committee Member</strong><br> <em>Graduate</em></p><p>Coordinated and managed class activities and support initiatives.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Hi~ I am &lt;strong&gt;Xiaochen Wang(王晓晨)&lt;/strong&gt;, a master student at the School of Software and Microelectronics, Peking University. I study</summary>
      
    
    
    
    
  </entry>
  
</feed>
